{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Lift Calculations\n",
    "This notebook is meant to be a simple example of performing dynamic univariate lift calculations. Given a dataset of observations, we'll designate one column as our outcome and evaluate the rest as univariate features. For each feature in the dataset, we will identify the top 20 most common values and calculate lift for each.\n",
    "\n",
    "To use this in your own analysis, you'll obviously need a CSV data file with your own observations. Be prepared to make some edits in the below, but the main analysis stage (identified below) should be completely generic and not need any editing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Input Data\n",
    "This open dataset provided by Airbnb (http://data.insideairbnb.com/united-states/nc/asheville/2019-02-17/data/listings.csv.gz) provides some detailed data for just over 2,000 rental listings. We're using only a subset of the columns and will use the rating score as our outcome.\n",
    "\n",
    "Note that the original file must be unzipped (gzip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = 'c:/users/rbagley/downloads/listings.csv'\n",
    "dataset = pd.read_csv(input_filepath, header=0, true_values = ['t'], false_values = ['f'],\n",
    "    usecols=[\n",
    "        'id', 'host_location', 'host_response_time', 'host_is_superhost','host_listings_count', \n",
    "        'host_has_profile_pic', 'host_identity_verified', 'neighbourhood_cleansed',\n",
    "        'zipcode', 'is_location_exact', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
    "        'beds', 'bed_type', 'price', 'minimum_nights', 'maximum_nights',\n",
    "        'review_scores_rating', 'instant_bookable', 'is_business_travel_ready',\n",
    "        'cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "* For sake of ease, let's reduce the review score from a 0-100 range to a boolean. Any score over 95 will be considered a positive rating\n",
    "* Create buckets out of pricing values, in $50 increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_rating(x):\n",
    "    if x >= 95: \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "dataset['positive_rating'] = dataset['review_scores_rating'].apply(is_positive_rating)\n",
    "dataset = dataset.drop(columns=['review_scores_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_price_group(x):\n",
    "    price_int = float(str(x).replace('$','').replace(',',''))\n",
    "    price_group = int(price_int / 50) * 50\n",
    "    return price_group\n",
    "\n",
    "dataset['price_group'] = dataset['price'].apply(create_price_group)\n",
    "dataset = dataset.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift Analysis\n",
    "Now, we'll iterate over each column to get some counts (totals and positive outcomes) per value in that column. Finally, we'll use these counts to get outcome probabilities per value and calculate lift per value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_col = 'positive_rating'\n",
    "id_col = 'id'\n",
    "feature_cols = ['host_location', 'host_response_time', 'host_is_superhost', 'host_listings_count', 'host_has_profile_pic', \n",
    "                'host_identity_verified', 'neighbourhood_cleansed', 'zipcode', 'is_location_exact', 'property_type', \n",
    "                'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'minimum_nights', 'maximum_nights', \n",
    "                'instant_bookable', 'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'price_group']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE!!!** Everything in this next code block is completely generic. No edits should be required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need some global counts\n",
    "total_count = len(dataset.index)\n",
    "total_positives = len(dataset[(dataset[outcome_col] == True)])\n",
    "\n",
    "# An empty list to hold the count results\n",
    "count_list = list()\n",
    "\n",
    "# Iterate over each feature to collect individual counts per value\n",
    "for feature in feature_cols:\n",
    "    counts_df = pd.DataFrame(dataset.groupby([feature,])[id_col].count()).nlargest(20,['id'])  # only top 20\n",
    "    counts_df.rename({'id': 'count'}, axis='columns', inplace=True)\n",
    "    positives_df = pd.DataFrame(dataset[(dataset[outcome_col] == True)].groupby([feature,])[id_col].count())  # all values\n",
    "    positives_df.rename({'id': 'positives'}, axis='columns', inplace=True)\n",
    "    # merge these dataframes\n",
    "    merge_df = counts_df.merge(positives_df, left_index=True, right_index=True)\n",
    "    # iterate over rows, building a dict per row, and append each to list of counts\n",
    "    for this_row in merge_df.iterrows():\n",
    "        this_dict = {\n",
    "            'feature': feature,\n",
    "            'value': str(this_row[0]),\n",
    "            'total_count': total_count,\n",
    "            'total_positives': total_positives,\n",
    "            'count': this_row[1]['count'],\n",
    "            'positives': this_row[1]['positives']\n",
    "        }\n",
    "        count_list.append(this_dict)\n",
    "\n",
    "# Create a new dataframe from the aggregated list\n",
    "lift_df = pd.DataFrame(count_list)\n",
    "\n",
    "# Now let's add some calculations for probabilities and lift per row\n",
    "lift_df['total_prob'] = lift_df['total_positives'] / lift_df['total_count']\n",
    "lift_df['prob'] = lift_df['positives'] / lift_df['count']\n",
    "lift_df['lift'] = lift_df['prob'] / lift_df['total_prob']\n",
    "lift_df['1/lift'] = 1 / lift_df['lift']\n",
    "lift_df['prct_total'] = lift_df['count'] / lift_df['total_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output CSV\n",
    "Push this final lift dataframe to a csv file for use elsewhere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = 'c:/users/rbagley/downloads/lift_output.csv'\n",
    "\n",
    "lift_df.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; Mackinac Data Group, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
